{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing customer messages\n",
    "\n",
    "This notebook demonstrates analyzing customer messages using Watson Natural Language Understanding - using default models.\n",
    "\n",
    "1. Look up Natural Language Understanding API key\n",
    "2. Analyze a test message\n",
    "3. Download sample customer messages \n",
    "4. Analyze sample customer messages\n",
    "5. Save results in a JSON file as a Project Asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Look up Natural Language Understanding API key and URL\n",
    "\n",
    "1. From the **Navigation menu** ( <img style=\"margin: 0px; padding: 0px; display: inline;\" src=\"https://github.com/spackows/CASCON-2019_NLP-workshops/raw/master/images/nav-menu-icon.png\"/> ), under the **Services** group, right-click \"Watson Services\" and then open the link in a new browser tab\n",
    "2. In the new Watson services tab, from the **Action** menu beside your Natural Language Understanding instance, select \"Manage in IBM Cloud\"\n",
    "3. In the service details page that opens, copy the apikey and URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey = \"\" # <-- PASTE YOUR APIKEY HERE\n",
    "url    = \"\" # <-- PASTE YOUR SERVICE URL HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Analyze a test message\n",
    "\n",
    "Use the NLU API to extract:\n",
    "- Sentiment\n",
    "- Emotion\n",
    "- Keywords\n",
    "- Entities\n",
    "- Categories\n",
    "- Concepts\n",
    "- Syntax\n",
    "- Semantics\n",
    "\n",
    "See:\n",
    "- [Watson Natural Language Understanding demo app](https://natural-language-understanding-demo.ng.bluemix.net/)\n",
    "- [Text anaytics features](https://cloud.ibm.com/apidocs/natural-language-understanding?code=python#text-analytics-features)\n",
    "- [Watson Natural Language Understanding API](https://cloud.ibm.com/apidocs/natural-language-understanding/natural-language-understanding?code=python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade \"ibm-watson>=4.0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a natural language understanding object\n",
    "#\n",
    "import json\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "from ibm_watson.natural_language_understanding_v1 import Features, ConceptsOptions, EmotionOptions, EntitiesOptions, KeywordsOptions, SemanticRolesOptions, SentimentOptions, CategoriesOptions, SyntaxOptions, SyntaxOptionsTokens\n",
    "authenticator = IAMAuthenticator( apikey )\n",
    "nlu = NaturalLanguageUnderstandingV1( version='2018-11-16', authenticator=authenticator )\n",
    "nlu.set_service_url( url )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore every NLU feature option using this test message\n",
    "text = \"My IBM Cloud account is in Dallas, but I'm in Europe.  My friend, Sam, says that's not supported.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"My IBM Cloud account is in Dallas, but I'm in Europe.  My friend, Sam, says that's not supported.\"\n",
      "\n",
      "{\n",
      "   \"score\": -0.650127,\n",
      "   \"label\": \"negative\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Sentiment\n",
    "result = nlu.analyze( text=text, features=Features( sentiment=SentimentOptions() ) ).get_result()\n",
    "print( '\"' + text + '\"' + \"\\n\" )\n",
    "print( json.dumps( result[\"sentiment\"][\"document\"], indent=3 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"My IBM Cloud account is in Dallas, but I'm in Europe.  My friend, Sam, says that's not supported.\"\n",
      "\n",
      "{\n",
      "   \"sadness\": 0.232996,\n",
      "   \"joy\": 0.059741,\n",
      "   \"fear\": 0.032187,\n",
      "   \"disgust\": 0.081764,\n",
      "   \"anger\": 0.03555\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Emotion\n",
    "result = nlu.analyze( text=text, features=Features( emotion=EmotionOptions() ) ).get_result()\n",
    "print( '\"' + text + '\"' + \"\\n\" )\n",
    "print( json.dumps( result[\"emotion\"][\"document\"][\"emotion\"], indent=3 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"My IBM Cloud account is in Dallas, but I'm in Europe.  My friend, Sam, says that's not supported.\"\n",
      "\n",
      "[\n",
      "   {\n",
      "      \"text\": \"IBM Cloud account\",\n",
      "      \"relevance\": 0.997981,\n",
      "      \"count\": 1\n",
      "   },\n",
      "   {\n",
      "      \"text\": \"friend\",\n",
      "      \"relevance\": 0.760324,\n",
      "      \"count\": 1\n",
      "   },\n",
      "   {\n",
      "      \"text\": \"Sam\",\n",
      "      \"relevance\": 0.651134,\n",
      "      \"count\": 1\n",
      "   },\n",
      "   {\n",
      "      \"text\": \"Dallas\",\n",
      "      \"relevance\": 0.601985,\n",
      "      \"count\": 1\n",
      "   },\n",
      "   {\n",
      "      \"text\": \"Europe\",\n",
      "      \"relevance\": 0.58449,\n",
      "      \"count\": 1\n",
      "   }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Keywords\n",
    "result = nlu.analyze( text=text, features=Features( keywords=KeywordsOptions() ) ).get_result()\n",
    "print( '\"' + text + '\"' + \"\\n\" )\n",
    "print( json.dumps( result[\"keywords\"], indent=3 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"My IBM Cloud account is in Dallas, but I'm in Europe.  My friend, Sam, says that's not supported.\"\n",
      "\n",
      "[\n",
      "   {\n",
      "      \"type\": \"Company\",\n",
      "      \"text\": \"IBM\",\n",
      "      \"relevance\": 0.859385,\n",
      "      \"count\": 1\n",
      "   },\n",
      "   {\n",
      "      \"type\": \"Person\",\n",
      "      \"text\": \"Sam\",\n",
      "      \"relevance\": 0.846087,\n",
      "      \"count\": 1\n",
      "   },\n",
      "   {\n",
      "      \"type\": \"Location\",\n",
      "      \"text\": \"Dallas\",\n",
      "      \"relevance\": 0.786843,\n",
      "      \"disambiguation\": {\n",
      "         \"subtype\": [\n",
      "            \"City\"\n",
      "         ]\n",
      "      },\n",
      "      \"count\": 1\n",
      "   },\n",
      "   {\n",
      "      \"type\": \"Location\",\n",
      "      \"text\": \"Europe\",\n",
      "      \"relevance\": 0.760723,\n",
      "      \"disambiguation\": {\n",
      "         \"subtype\": [\n",
      "            \"MusicalGroup\",\n",
      "            \"BroadcastArtist\",\n",
      "            \"FilmMusicContributor\",\n",
      "            \"Lyricist\",\n",
      "            \"MusicalArtist\",\n",
      "            \"RecordProducer\",\n",
      "            \"Continent\"\n",
      "         ],\n",
      "         \"name\": \"Europe\",\n",
      "         \"dbpedia_resource\": \"http://dbpedia.org/resource/Europe\"\n",
      "      },\n",
      "      \"count\": 1\n",
      "   }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Entities\n",
    "result = nlu.analyze( text=text, features=Features( entities=EntitiesOptions() ) ).get_result()\n",
    "print( '\"' + text + '\"' + \"\\n\" )\n",
    "print( json.dumps( result[\"entities\"], indent=3 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"My IBM Cloud account is in Dallas, but I'm in Europe.  My friend, Sam, says that's not supported.\"\n",
      "\n",
      "[\n",
      "   {\n",
      "      \"score\": 0.883607,\n",
      "      \"label\": \"/technology and computing/operating systems\"\n",
      "   },\n",
      "   {\n",
      "      \"score\": 0.814576,\n",
      "      \"label\": \"/technology and computing/hardware/computer\"\n",
      "   },\n",
      "   {\n",
      "      \"score\": 0.789138,\n",
      "      \"label\": \"/technology and computing/hardware/computer peripherals\"\n",
      "   }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Categories\n",
    "result = nlu.analyze( text=text, features=Features( categories=CategoriesOptions() ) ).get_result()\n",
    "print( '\"' + text + '\"' + \"\\n\" )\n",
    "print( json.dumps( result[\"categories\"], indent=3 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"My IBM Cloud account is in Dallas, but I'm in Europe.  My friend, Sam, says that's not supported.\"\n",
      "\n",
      "[\n",
      "   {\n",
      "      \"text\": \"United States\",\n",
      "      \"relevance\": 0.916595,\n",
      "      \"dbpedia_resource\": \"http://dbpedia.org/resource/United_States\"\n",
      "   }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Concepts\n",
    "result = nlu.analyze( text=text, features=Features( concepts=ConceptsOptions() ) ).get_result()\n",
    "print( '\"' + text + '\"' + \"\\n\" )\n",
    "print( json.dumps( result[\"concepts\"], indent=3 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"My IBM Cloud account is in Dallas, but I'm in Europe.  My friend, Sam, says that's not supported.\"\n",
      "\n",
      "[\n",
      "   {\n",
      "      \"text\": \"My\",\n",
      "      \"part_of_speech\": \"PRON\",\n",
      "      \"location\": [\n",
      "         0,\n",
      "         2\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \"IBM\",\n",
      "      \"part_of_speech\": \"PROPN\",\n",
      "      \"location\": [\n",
      "         3,\n",
      "         6\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \"Cloud\",\n",
      "      \"part_of_speech\": \"PROPN\",\n",
      "      \"location\": [\n",
      "         7,\n",
      "         12\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \"account\",\n",
      "      \"part_of_speech\": \"NOUN\",\n",
      "      \"location\": [\n",
      "         13,\n",
      "         20\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \"is\",\n",
      "      \"part_of_speech\": \"AUX\",\n",
      "      \"location\": [\n",
      "         21,\n",
      "         23\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \"in\",\n",
      "      \"part_of_speech\": \"ADP\",\n",
      "      \"location\": [\n",
      "         24,\n",
      "         26\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \"Dallas\",\n",
      "      \"part_of_speech\": \"NOUN\",\n",
      "      \"location\": [\n",
      "         27,\n",
      "         33\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \",\",\n",
      "      \"part_of_speech\": \"PUNCT\",\n",
      "      \"location\": [\n",
      "         33,\n",
      "         34\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \"but\",\n",
      "      \"part_of_speech\": \"CCONJ\",\n",
      "      \"location\": [\n",
      "         35,\n",
      "         38\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \"I\",\n",
      "      \"part_of_speech\": \"PRON\",\n",
      "      \"location\": [\n",
      "         39,\n",
      "         40\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \"'m\",\n",
      "      \"part_of_speech\": \"AUX\",\n",
      "      \"location\": [\n",
      "         40,\n",
      "         42\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \"in\",\n",
      "      \"part_of_speech\": \"ADP\",\n",
      "      \"location\": [\n",
      "         43,\n",
      "         45\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \"Europe\",\n",
      "      \"part_of_speech\": \"PROPN\",\n",
      "      \"location\": [\n",
      "         46,\n",
      "         52\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \".\",\n",
      "      \"part_of_speech\": \"PUNCT\",\n",
      "      \"location\": [\n",
      "         52,\n",
      "         53\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \"My\",\n",
      "      \"part_of_speech\": \"PRON\",\n",
      "      \"location\": [\n",
      "         55,\n",
      "         57\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \"friend\",\n",
      "      \"part_of_speech\": \"NOUN\",\n",
      "      \"location\": [\n",
      "         58,\n",
      "         64\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \",\",\n",
      "      \"part_of_speech\": \"PUNCT\",\n",
      "      \"location\": [\n",
      "         64,\n",
      "         65\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \"Sam\",\n",
      "      \"part_of_speech\": \"PROPN\",\n",
      "      \"location\": [\n",
      "         66,\n",
      "         69\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \",\",\n",
      "      \"part_of_speech\": \"PUNCT\",\n",
      "      \"location\": [\n",
      "         69,\n",
      "         70\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \"says\",\n",
      "      \"part_of_speech\": \"VERB\",\n",
      "      \"location\": [\n",
      "         71,\n",
      "         75\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \"that\",\n",
      "      \"part_of_speech\": \"PRON\",\n",
      "      \"location\": [\n",
      "         76,\n",
      "         80\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \"'s\",\n",
      "      \"part_of_speech\": \"AUX\",\n",
      "      \"location\": [\n",
      "         80,\n",
      "         82\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \"not\",\n",
      "      \"part_of_speech\": \"PART\",\n",
      "      \"location\": [\n",
      "         83,\n",
      "         86\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \"supported\",\n",
      "      \"part_of_speech\": \"VERB\",\n",
      "      \"location\": [\n",
      "         87,\n",
      "         96\n",
      "      ]\n",
      "   },\n",
      "   {\n",
      "      \"text\": \".\",\n",
      "      \"part_of_speech\": \"PUNCT\",\n",
      "      \"location\": [\n",
      "         96,\n",
      "         97\n",
      "      ]\n",
      "   }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Syntax\n",
    "result = nlu.analyze( text=text, features=Features( syntax=SyntaxOptions( tokens=SyntaxOptionsTokens( part_of_speech=True ) ) ) ).get_result()\n",
    "print( '\"' + text + '\"' + \"\\n\" )\n",
    "print( json.dumps( result[\"syntax\"][\"tokens\"], indent=3 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"My IBM Cloud account is in Dallas, but I'm in Europe.  My friend, Sam, says that's not supported.\"\n",
      "\n",
      "[\n",
      "   {\n",
      "      \"subject\": {\n",
      "         \"text\": \"My IBM Cloud account\"\n",
      "      },\n",
      "      \"sentence\": \"My IBM Cloud account is in Dallas, but I'm in Europe.\",\n",
      "      \"object\": {\n",
      "         \"text\": \"in Dallas\"\n",
      "      },\n",
      "      \"action\": {\n",
      "         \"verb\": {\n",
      "            \"text\": \"be\",\n",
      "            \"tense\": \"present\"\n",
      "         },\n",
      "         \"text\": \"is\",\n",
      "         \"normalized\": \"be\"\n",
      "      }\n",
      "   },\n",
      "   {\n",
      "      \"subject\": {\n",
      "         \"text\": \"I\"\n",
      "      },\n",
      "      \"sentence\": \"My IBM Cloud account is in Dallas, but I'm in Europe.\",\n",
      "      \"action\": {\n",
      "         \"verb\": {\n",
      "            \"text\": \"be\",\n",
      "            \"tense\": \"present\"\n",
      "         },\n",
      "         \"text\": \"am\",\n",
      "         \"normalized\": \"be\"\n",
      "      }\n",
      "   },\n",
      "   {\n",
      "      \"subject\": {\n",
      "         \"text\": \"My friend, Sam,\"\n",
      "      },\n",
      "      \"sentence\": \" My friend, Sam, says that's not supported.\",\n",
      "      \"object\": {\n",
      "         \"text\": \"that's not supported\"\n",
      "      },\n",
      "      \"action\": {\n",
      "         \"verb\": {\n",
      "            \"text\": \"say\",\n",
      "            \"tense\": \"present\"\n",
      "         },\n",
      "         \"text\": \"says\",\n",
      "         \"normalized\": \"say\"\n",
      "      }\n",
      "   }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Semantics\n",
    "result = nlu.analyze( text=text, features=Features( semantic_roles=SemanticRolesOptions() ) ).get_result()\n",
    "print( '\"' + text + '\"' + \"\\n\" )\n",
    "print( json.dumps( result[\"semantic_roles\"], indent=3 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Import sample customer messages\n",
    "\n",
    "This sample data set is from the Watson Studio Gallary: [Customer messages](https://dataplatform.cloud.ibm.com/exchange/public/entry/view/015ddef6a868441188268a123404f744)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>excuse me</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good evening</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good morning</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good morning</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good morning can you help me upload a shapefile?</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0         1\n",
       "0                                         excuse me        hi\n",
       "1                                      Good evening        hi\n",
       "2                                      Good morning        hi\n",
       "3                                      good morning        hi\n",
       "4  Good morning can you help me upload a shapefile?  question"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data into a DataFrame by reading from a URL\n",
    "#\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "url = \"https://api.dataplatform.cloud.ibm.com/v2/gallery-assets/entries/015ddef6a868441188268a123404f744/data?accessKey=1e878a1edda3c1c8b3f9defb83e5c84b\"\n",
    "csv_contents = io.StringIO( requests.get( url ).content.decode( \"utf-8\" ) )\n",
    "all_messages = pd.read_csv( csv_contents, header=None )\n",
    "all_messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good morning can you help me upload a shapefile?',\n",
       " 'Good night where to place my file to import it into notebook?',\n",
       " 'hai how can i do analyze with csv file is there any tutorial on it',\n",
       " 'Having issues setup WML service',\n",
       " 'hello - Im trying to edit a notebook and the circie just keeps spinning. any idea to get around this?',\n",
       " 'hello how can i download a csv file from my notebook?']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For analysis purposes, we want just the questions and problems, \n",
    "# not the short, social messages labeled as \"hi\". And we want just \n",
    "# the text of those questions and problems, not the labels column.\n",
    "#\n",
    "questions_problems_only = all_messages[all_messages.iloc[:,1] != \"hi\" ].reset_index(drop=True)\n",
    "questions_problems_text = list( questions_problems_only.iloc[:,0] )\n",
    "questions_problems_text[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Analyze sample customer messages\n",
    "\n",
    "For our analysis, we'll focus on extracting:\n",
    "- Keywords \n",
    "- Actions and Objects (from semantic roles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all sample customer questions and problems, extracting keywords and sematic roles\n",
    "#\n",
    "results_list = []\n",
    "for message in questions_problems_text:\n",
    "    result = nlu.analyze( text=message, features=Features( keywords=KeywordsOptions(), semantic_roles=SemanticRolesOptions() ) ).get_result()\n",
    "    actions_arr = []\n",
    "    keywords_arr = []\n",
    "    for keyword in result[\"keywords\"]:\n",
    "        keywords_arr.append( keyword[\"text\"] )\n",
    "    if( \"semantic_roles\" in result ):\n",
    "        for semantic_result in result[\"semantic_roles\"]:\n",
    "            if( \"action\" in semantic_result ):\n",
    "                actions_arr.append( semantic_result[\"action\"][\"normalized\"] )\n",
    "    results_list.append( { \"header\"   : \"-------------------------------------------------------------\",\n",
    "                           \"message\"  : message,\n",
    "                           \"actions\"  : actions_arr,\n",
    "                           \"keywords\" : keywords_arr,\n",
    "                           \"spacer\"   : \"\" } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'header': '-------------------------------------------------------------',\n",
       "  'message': 'Good morning can you help me upload a shapefile?',\n",
       "  'actions': ['help'],\n",
       "  'keywords': ['Good morning', 'shapefile'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Good night where to place my file to import it into notebook?',\n",
       "  'actions': ['to place', 'to import'],\n",
       "  'keywords': ['Good night', 'file', 'notebook'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'hai how can i do analyze with csv file is there any tutorial on it',\n",
       "  'actions': ['do', 'be'],\n",
       "  'keywords': ['csv file', 'hai', 'tutorial'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Having issues setup WML service',\n",
       "  'actions': [],\n",
       "  'keywords': ['issues setup WML service'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'hello - Im trying to edit a notebook and the circie just keeps spinning. any idea to get around this?',\n",
       "  'actions': ['try', 'try to edit', 'keep'],\n",
       "  'keywords': ['Im', 'idea', 'notebook', 'circie'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'hello how can i download a csv file from my notebook?',\n",
       "  'actions': ['download'],\n",
       "  'keywords': ['csv file', 'notebook'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hello How can I use deployed models built with R studio in WML?',\n",
       "  'actions': ['use', 'deploy'],\n",
       "  'keywords': ['R studio', 'models', 'WML'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'hello how to start creating R notebook?',\n",
       "  'actions': ['to start create'],\n",
       "  'keywords': ['R notebook'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hello I am having trouble logging in',\n",
       "  'actions': ['be', 'be have'],\n",
       "  'keywords': ['trouble'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hello I can connect to clodant from pyspark',\n",
       "  'actions': [],\n",
       "  'keywords': ['pyspark'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'hello I cannot create a Notebook',\n",
       "  'actions': ['create'],\n",
       "  'keywords': ['Notebook'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hello I keep getting error when trying to create account. Can you help me with that?',\n",
       "  'actions': ['keep', 'keep get', 'try', 'try to create', 'help'],\n",
       "  'keywords': ['error', 'account'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hello im doing this tutorial Predict the best drug for heart treatment with IBM Watson Machine Learning (SPSS) and Im having some trouble to reproduce the example',\n",
       "  'actions': ['have'],\n",
       "  'keywords': ['IBM Watson Machine Learning',\n",
       "   'best drug',\n",
       "   'heart treatment',\n",
       "   'tutorial',\n",
       "   'trouble',\n",
       "   'example',\n",
       "   'SPSS',\n",
       "   'Im'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hello Im trying to upload one 1.5GB tar.gz file and unzip to Object Storage. Could you tell me how to do it?',\n",
       "  'actions': ['try', 'try to upload', 'tell', 'to do'],\n",
       "  'keywords': ['1.5GB tar.gz file', 'Object Storage', 'Im'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'hello message keeps coming which says my services have exceeded limit',\n",
       "  'actions': ['keep'],\n",
       "  'keywords': ['message keeps', 'services', 'limit'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hello... i created a Cloudent NoSQL DB and loaded csv in it now how to access the data',\n",
       "  'actions': ['create', 'load'],\n",
       "  'keywords': ['Cloudent NoSQL DB', 'data', 'loaded csv'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi cant login today with this err The owners accout is not active. This might be caused by expired membership.',\n",
       "  'actions': ['be', 'might be cause'],\n",
       "  'keywords': ['cant login today', 'membership', 'owners accout', 'err'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi fine I was having difficulty uploading data but its working now',\n",
       "  'actions': ['be have', 'upload'],\n",
       "  'keywords': ['difficulty', 'data'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi how can I import a flow from spss modeler in watson studio?',\n",
       "  'actions': ['import'],\n",
       "  'keywords': ['spss modeler', 'flow', 'watson studio'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi how do you add a folder of files to a project?',\n",
       "  'actions': ['add'],\n",
       "  'keywords': ['folder of files', 'project'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi I am trying to Import Github Code To Create NoteBook via Github link but the file format is not accepting',\n",
       "  'actions': ['be try to Import', 'be'],\n",
       "  'keywords': ['Github Code', 'file format', 'NoteBook', 'Github link'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi I am trying to request a new API token but I dont know what the ID should be for me',\n",
       "  'actions': ['be try to request', 'know'],\n",
       "  'keywords': ['new API token', 'ID'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi I created a csv in my notebook but how do I download it to my laptop?',\n",
       "  'actions': ['create', 'download'],\n",
       "  'keywords': ['csv', 'notebook', 'laptop'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi I got the message failed to prepare Object-Storage. Would you please give me a suggestion. Thank you.',\n",
       "  'actions': ['get', 'fail', 'fail to prepare', 'please give'],\n",
       "  'keywords': ['Object-Storage', 'message', 'suggestion'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi I have some problems initiate my notebook in my project',\n",
       "  'actions': ['have'],\n",
       "  'keywords': ['problems', 'notebook', 'project'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi I need help establishing connection with my cloudant account. I get an error saying Failed to find data source',\n",
       "  'actions': ['need', 'establish', 'get', 'say'],\n",
       "  'keywords': ['data source',\n",
       "   'cloudant account',\n",
       "   'error',\n",
       "   'help',\n",
       "   'connection'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'hi i need help writing my dataframe to Db2',\n",
       "  'actions': ['need', 'write'],\n",
       "  'keywords': ['Db2', 'help', 'dataframe'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi i need some help when model training they are giving me error on training',\n",
       "  'actions': ['need', 'be', 'be give'],\n",
       "  'keywords': ['model training', 'help', 'error', 'training'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi I want to know hoe to use APIs',\n",
       "  'actions': ['want', 'want to know', 'to use'],\n",
       "  'keywords': ['hoe', 'APIs'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi I want to know how to make connection to database',\n",
       "  'actions': ['want', 'want to know', 'to make'],\n",
       "  'keywords': ['connection', 'database'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi I wanted to know how to export data from python notebooks?',\n",
       "  'actions': ['want', 'want to know', 'to export'],\n",
       "  'keywords': ['python notebooks', 'data'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi I was trying to deploy a model from a notebook. When I run this line it gave me an erro: Invalid token format. Could u help me? Thanks.',\n",
       "  'actions': ['be', 'try', 'be try to deploy', 'run', 'give', 'help'],\n",
       "  'keywords': ['Invalid token format',\n",
       "   'line',\n",
       "   'model',\n",
       "   'notebook',\n",
       "   'Thanks',\n",
       "   'erro'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi I would like to signup for a trail but I am getting an error',\n",
       "  'actions': ['like', 'be'],\n",
       "  'keywords': ['trail', 'error'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi im having some troubles with a shiny app',\n",
       "  'actions': [],\n",
       "  'keywords': ['shiny app', 'troubles'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi Im having trouble calling the endpoint of my deployed model',\n",
       "  'actions': ['have', 'call'],\n",
       "  'keywords': ['Im', 'trouble', 'endpoint', 'model'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi is any way to download my files in data assets back to my loacal machine?',\n",
       "  'actions': [],\n",
       "  'keywords': ['way', 'data assets', 'files', 'loacal machine'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'hi is there link on how to deploy a data analytic model using node-red?',\n",
       "  'actions': ['be'],\n",
       "  'keywords': ['analytic model', 'link', 'data', 'node-red'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi l couldnt able to create a new project',\n",
       "  'actions': ['to create'],\n",
       "  'keywords': ['new project', 'couldnt'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi My problem is an error when I want to create a new notebook',\n",
       "  'actions': ['be', 'want'],\n",
       "  'keywords': ['problem', 'new notebook', 'error'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'hi my trial has expired can you help?',\n",
       "  'actions': ['have'],\n",
       "  'keywords': ['trial'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi not able to signup',\n",
       "  'actions': [],\n",
       "  'keywords': ['signup'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi team how can i import data into a project?',\n",
       "  'actions': ['import'],\n",
       "  'keywords': ['team', 'data', 'project'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi team How can you change the name of a Notebook?',\n",
       "  'actions': ['change'],\n",
       "  'keywords': ['team', 'name of a Notebook'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi there can i recover a deleted notebook?',\n",
       "  'actions': ['recover'],\n",
       "  'keywords': ['notebook'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi there how can I upload a series of .zip files then unzip them?',\n",
       "  'actions': ['upload', 'unzip'],\n",
       "  'keywords': ['zip files', 'series'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi there Im having trouble using my CSV data for my machine learning model',\n",
       "  'actions': ['have', 'use'],\n",
       "  'keywords': ['CSV data', 'trouble', 'machine', 'Im', 'model'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi trying to create a note book it is giving error',\n",
       "  'actions': ['be', 'be give'],\n",
       "  'keywords': ['note book', 'error'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Hi when I tried to create a project am getting below error can you pls guide here',\n",
       "  'actions': ['try', 'try to create', 'guide'],\n",
       "  'keywords': ['project am', 'error', 'pls guide'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'how can i extend my trial period',\n",
       "  'actions': ['extend'],\n",
       "  'keywords': ['trial period'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'How do I add collaborators to my project please?',\n",
       "  'actions': ['do', 'add'],\n",
       "  'keywords': ['collaborators', 'project'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'how do i save my data as a csv file',\n",
       "  'actions': ['save'],\n",
       "  'keywords': ['csv file', 'data'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'How do I start using Watson Machine Learning',\n",
       "  'actions': ['start use'],\n",
       "  'keywords': ['Watson Machine Learning'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'How to acess the data in jupyter notebook using pandas?',\n",
       "  'actions': ['to acess', 'use'],\n",
       "  'keywords': ['jupyter notebook', 'data', 'pandas'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'how to export to csv in notebook?',\n",
       "  'actions': ['csv'],\n",
       "  'keywords': ['csv', 'notebook'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'How to start creating R notebook?',\n",
       "  'actions': [],\n",
       "  'keywords': ['R notebook'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'How to upload a dataset from local to RStudio',\n",
       "  'actions': ['to upload'],\n",
       "  'keywords': ['dataset', 'RStudio'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'I am not able to register my account need your help',\n",
       "  'actions': ['be', 'to register'],\n",
       "  'keywords': ['account', 'help'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'i am Student can i have free access',\n",
       "  'actions': ['be'],\n",
       "  'keywords': ['free access', 'Student'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'I cant see my  spark instance when i go to create a new project',\n",
       "  'actions': ['cant see', 'go to create'],\n",
       "  'keywords': ['spark instance', 'new project'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'I deployed my WatsonML model and have a Scoring End Point that Id like to use from an external app. I keep getting Authentication Failed when I try to invoke it.',\n",
       "  'actions': ['deploy',\n",
       "   'have',\n",
       "   'to use',\n",
       "   'keep get',\n",
       "   'keep get',\n",
       "   'try',\n",
       "   'try to invoke'],\n",
       "  'keywords': ['WatsonML model',\n",
       "   'Scoring End Point',\n",
       "   'Authentication Failed',\n",
       "   'external app',\n",
       "   'Id'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'I get error like Exceeded Services Limit',\n",
       "  'actions': ['get'],\n",
       "  'keywords': ['Services Limit', 'error'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'I got errors  from SPSS modelerabout connecting to the server how I can solve this issue',\n",
       "  'actions': ['get', 'can solve'],\n",
       "  'keywords': ['SPSS modelerabout', 'errors', 'server', 'issue'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'I keep getting a Failed creating account error',\n",
       "  'actions': ['keep', 'keep get', 'create'],\n",
       "  'keywords': ['account error'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Im following the example it says that I can upload to spark but when I try it says unable to create a new link what am I doing wrong?',\n",
       "  'actions': ['say', 'say', 'be'],\n",
       "  'keywords': ['example', 'new link', 'Im'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Im trying to create a python notebook and keep getting an error',\n",
       "  'actions': ['try', 'try to create'],\n",
       "  'keywords': ['python notebook', 'error', 'Im'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Is It possible to insert an external source to create Notebook?',\n",
       "  'actions': ['Is'],\n",
       "  'keywords': ['external source', 'Notebook'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Is there any free plan for students?',\n",
       "  'actions': ['Is'],\n",
       "  'keywords': ['free plan', 'students'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'jupyter notebook is unable to connect to kernel',\n",
       "  'actions': ['connect'],\n",
       "  'keywords': ['jupyter notebook', 'kernel'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'Uploading data from object storage to rstudio returns an error',\n",
       "  'actions': [],\n",
       "  'keywords': ['object storage', 'data', 'error', 'rstudio'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'What library do I use to run Sparks Machine Learning library on R in?',\n",
       "  'actions': ['do', 'to run'],\n",
       "  'keywords': ['Sparks Machine Learning library', 'library'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'When I insert connection to a file in R I get errors trying to run it',\n",
       "  'actions': ['insert', 'get', 'try', 'try to run'],\n",
       "  'keywords': ['connection', 'file', 'errors'],\n",
       "  'spacer': ''},\n",
       " {'header': '-------------------------------------------------------------',\n",
       "  'message': 'When I try to add a model to any project I get an Unauthorized error.',\n",
       "  'actions': ['try', 'try to add'],\n",
       "  'keywords': ['Unauthorized error', 'model', 'project'],\n",
       "  'spacer': ''}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Save results\n",
    "\n",
    "Save NLU results in a JSON file as a Project Asset.\n",
    "\n",
    "To be able to easily save questions in .csv files as assets in our Watson Studio project, we need a project token.\n",
    "\n",
    "Follow the steps in this topic: [Adding a project token](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/token.html?audience=wdp&context=data)\n",
    "\n",
    "***The project token is added in the very first cell at the top of the notebook.  Don't forget to scroll up and run that cell.***\n",
    "\n",
    "(If you forget to run the inserted cell, you'll see the error <code>name 'project' is not defined</code> when you try to run the next cell below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'NLU-results.json',\n",
       " 'message': 'File saved to project storage.',\n",
       " 'bucket_name': 'cascon2019-donotdelete-pr-gsnhbqe4skdcxh',\n",
       " 'asset_id': '2d1dd212-4308-40ab-88f4-8206620b2a9c'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.save_data( 'NLU-results.json', json.dumps( results_list, indent=3 ) , overwrite=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright Â© 2019 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
